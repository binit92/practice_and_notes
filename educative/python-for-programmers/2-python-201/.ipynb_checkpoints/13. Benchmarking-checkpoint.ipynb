{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it mean to benchmark ones code? The main idea behind benchmarking or profiling is to figure out how fast your code executes and where the bottlenecks are. The main reason to do this sort of thing is for optimization. You will run into situations where you need your code to run faster because your business needs have changed. When this happens, you will need to figure out what parts of your code are slowing it down.\n",
    "\n",
    "This chapter will only cover how to profile your code using a variety of tools. It will not go into actually optimizing your code. Let’s get started!\n",
    "\n",
    "### timeit\n",
    "Python comes with a module called **timeit**. You can use it to time small code snippets. The timeit module uses platform-specific time functions so that you will get the most accurate timings possible.\n",
    "\n",
    "The timeit module has a command line interface, but it can also be imported. We will start out by looking at how to use timeit from the command line. Open up a terminal and try the following examples:\n",
    "\n",
    "> python -m timeit -s “[ord(x) for x in ‘abcdfghi’]” 100000000 loops, best of 3: 0.0115 usec per loop\n",
    "\n",
    "> python -m timeit -s “[chr(int(x)) for x in ‘123456789’]” 100000000 loops, best of 3: 0.0119 usec per loop\n",
    "\n",
    "What’s going on here? Well, when you call Python on the command line and pass it the “-m” option, you are telling it to look up a module and use it as the main program. The “-s” tells the timeit module to run setup once. Then it runs the code for n number of loops 3 times and returns the best average of the 3 runs. For these silly examples, you won’t see much difference.\n",
    "\n",
    "Your output will likely be slightly different as it is dependent on your computer’s specifications.\n",
    "\n",
    "Let’s write a silly function and see if we can time it from the command line:\n",
    "\n",
    "```\n",
    "# simple_func.py\n",
    "def my_function():\n",
    "    try:\n",
    "        1 / 0\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "```\n",
    "\n",
    "All this function does is cause an error that is promptly ignored. Yes, it’s another silly example. To get timeit to run this code on the command line, we will need to import the code into its namespace, so make sure you have changed your current working directory to be in the same folder that this script is in. Then run the following:\n",
    "\n",
    "> python -m timeit \"import simple_func; simple_func.my_function()\" 1000000 loops, best of 3: 1.77 usec per loop\n",
    "\n",
    "Here we import the function and then call it. Note that we separate the import and the function call with semi-colons and that the Python code is in quotes. Now we’re ready to learn how to use timeit inside an actual Python script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing timeit for Testing \n",
    "\n",
    "Using the timeit module inside your code is also pretty easy. We’ll use the same silly script from before and show you how below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509414396000011\n"
     ]
    }
   ],
   "source": [
    "def my_function():\n",
    "    try:\n",
    "        1 / 0\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import timeit\n",
    "    setup = \"from __main__ import my_function\"\n",
    "    print(timeit.timeit(\"my_function()\", setup=setup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check to see if the script is being run directly (i.e. not imported). If it is, then we import timeit, create a setup string to import the function into timeit’s namespace and then we call timeit.timeit. You will note that we pass a call to the function in quotes, then the setup string. And that’s really all there is to it! Now let’s learn about how to write our own timer decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a decorator \n",
    "\n",
    "Writing your own timer is a lot of fun too, although it may not be as accurate as just using timeit depending on the use case. Regardless, we’re going to write our own custom function timing decorator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The runtime for long_runner took 13.002413034439087 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def timerfunc(func):\n",
    "    \"\"\"\n",
    "    A timer decorator\n",
    "    \"\"\"\n",
    "    def function_timer(*args, **kwargs):\n",
    "        \"\"\"\n",
    "        A nested function for timing other functions\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        value = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        runtime = end - start\n",
    "        msg = \"The runtime for {func} took {time} seconds to complete\"\n",
    "        print(msg.format(func=func.__name__,\n",
    "                         time=runtime))\n",
    "        return value\n",
    "    return function_timer\n",
    "\n",
    "\n",
    "@timerfunc\n",
    "def long_runner():\n",
    "    for x in range(5):\n",
    "        sleep_time = random.choice(range(1,5))\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    long_runner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we import the **random** and the **time** modules from Python’s standard library. Then we create our decorator function. You will notice that it accepts a function and has another function inside of it. The nested function will grab the time before calling the passed in function. Then it waits for the function to return and grabs the end time. Now we know how long the function took to run, so we print it out. Of course, the decorator also needs to return the result of the function call and the function itself, so that’s what the last two statements are all about.\n",
    "\n",
    "The next function is decorated with our timing decorator. You will note that it uses random to “randomly” sleep a few seconds. This is just to demonstrate a long running program. You would actually want to time functions that connect to databases (or run large queries), websites, run threads or do other things that take a while to complete.\n",
    "\n",
    "Each time you run this code, the result will be slightly different. Give it a try and see for yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Timing Context Manager\n",
    "\n",
    "Some programmers like to use context managers to time small pieces of code. So let’s create our own timer context manager class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function took 14.003057956695557 seconds to complete\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "class MyTimer():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        end = time.time()\n",
    "        runtime = end - self.start\n",
    "        msg = 'The function took {time} seconds to complete'\n",
    "        print(msg.format(time=runtime))\n",
    "\n",
    "\n",
    "def long_runner():\n",
    "    for x in range(5):\n",
    "        sleep_time = random.choice(range(1,5))\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with MyTimer():\n",
    "        long_runner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use the class’s __init__ method to start our timer. The __enter__ method doesn’t need to do anything other then return itself. Lastly, the __exit__ method has all the juicy bits. Here we grab the end time, calculate the total run time and print it out.\n",
    "\n",
    "The end of the code actually shows an example of using our context manager where we wrap the function from the previous example in our custom context manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cProfile\n",
    "\n",
    "Python comes with its own code profilers built-in. There is the **profile** module and the **cProfile** module. The profile module is pure Python, but it will add a lot of overhead to anything you profile, so it’s usually recommended that you go with cProfile, which has a similar interface but is much faster.\n",
    "\n",
    "We’re not going to go into a lot of detail about this module in this chapter, but let’s look at a couple of fun examples so you get a taste for what it can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "cProfile.run(\"[x for x in range(1500)]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s break this down a bit. The first line shows that there were 4 function calls. The next line tells us how the results are ordered. According to the documentation, standard name refers to the far right column. There are a number of columns here.\n",
    "\n",
    "+ ncalls is the number of calls made.\n",
    "+ tottime is a total of the time spent in the given function.\n",
    "+ percall refers to the quotient of tottime divided by ncalls\n",
    "+ cumtime is the cumulative time spent in this and all subfunctions. It’s even accurate for recursive functions!\n",
    "+ The second percall column is the quotient of cumtime divided by primitive calls\n",
    "+ filename:lineno(function) provides the respective data of each function\n",
    "\n",
    "You can call cProfile on the command line in much the same way as we did with the timeit module. The main difference is that you would pass a Python script to it instead of just passing a snippet. Here’s an example call:\n",
    "\n",
    "`python -m cProfile test.py`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line_profiler\n",
    "\n",
    "There’s a neat 3rd party project called line_profiler that is designed to profile the time each individual line takes to execute. It also includes a script called kernprof for profiling Python applications and scripts using line_profiler. Just use pip to install the package. Here’s how:\n",
    "\n",
    "`pip install line_profiler`\n",
    "\n",
    "To actually use the line_profiler, we will need some code to profile. But first, I need to explain how line_profiler works when you call it on the command line. You will actually be calling line_profiler by calling the kernprof script. I thought that was a bit confusing the first time I used it, but that’s just the way it works. Here’s the normal way to use it:\n",
    "\n",
    "`kernprof -l silly_functions.py`\n",
    "\n",
    "This will print out the following message when it finishes: Wrote profile results to silly_functions.py.lprof. This is a binary file that we can’t view directly. When we run kernprof though, it will actually inject an instance of **LineProfiler** into your script’s **\\_\\_builtins\\_\\_** namespace. The instance will be named **profile** and is meant to be used as a decorator. With that in mind, we can actually write our script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a fast function!\n",
      "I'm a slow function\n"
     ]
    }
   ],
   "source": [
    "# silly_functions.py\n",
    "import time\n",
    "\n",
    "#@profile\n",
    "def fast_function():\n",
    "    print(\"I'm a fast function!\")\n",
    "\n",
    "#@profile\n",
    "def slow_function():\n",
    "    time.sleep(2)\n",
    "    print(\"I'm a slow function\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fast_function()\n",
    "    slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o now we have two decorated functions that are decorated with something that isn’t imported. If you actually try to run this script as is, you will get a **NameError** because “profile” is not defined. So always remember to remove your decorators after you have profiled your code!\n",
    "\n",
    "Let’s back up and learn how to actually view the results of our profiler. There are two methods we can use. The first is to use the line_profiler module to read our results file:\n",
    "\n",
    "`python -m line_profiler silly_functions.py.lprof`\n",
    "\n",
    "The alternate method is to just use kernprof in verbose mode by passing is -v:\n",
    "\n",
    "`kernprof -l -v silly_functions.py `\n",
    "\n",
    "Regardless which method you use, you should end up seeing something like the following get printed to your screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I'm a fast function!\n",
    "I'm a slow function\n",
    "Wrote profile results to silly_functions.py.lprof\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 3.4e-05 s\n",
    "File: silly_functions.py\n",
    "Function: fast_function at line 3\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     3                                           @profile\n",
    "     4                                           def fast_function():\n",
    "     5         1           34     34.0    100.0      print(\"I'm a fast function!\")\n",
    "\n",
    "Total time: 2.001 s\n",
    "File: silly_functions.py\n",
    "Function: slow_function at line 7\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     7                                           @profile\n",
    "     8                                           def slow_function():\n",
    "     9         1      2000942 2000942.0    100.0      time.sleep(2)\n",
    "    10         1           59     59.0      0.0      print(\"I'm a slow function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the source code is printed out with the timing information for each line. There are six columns of information here. Let’s find out what each one means.\n",
    "\n",
    "+ Line # - The line number of the code that was profiled\n",
    "+ Hits - The number of times that particular line was executed\n",
    "+ Time - The total amount of time the line took to execute (in the timer’s unit). The timer unit can be seen at the beginning of the output\n",
    "+ Per Hit - The average amount of time that line of code took to execute (in timer units)\n",
    "+ % Time - The percentage of time spent on the line relative to the total amount of time spent in said function\n",
    "+ Line Contents - The actual source code that was executed\n",
    "\n",
    "If you happen to be an IPython user, then you might want to know that IPython has a magic command (%lprun) that allows you to specify functions to profile and even which statement to execute.\n",
    "\n",
    "We saw the %timeit line-magic and %%timeit cell-magic in the introduction to magic functions in [IPython Magic Commands](https://jakevdp.github.io/PythonDataScienceHandbook/01.03-magic-commands.html); it can be used to time the repeated execution of snippets of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.82 µs ± 137 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766 ms ± 50.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.81 ms ± 581 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "%timeit L.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting an unsorted list:\n",
      "Wall time: 32 ms\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "print(\"sorting an unsorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorting an already sorted list:\n",
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"sorting an already sorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For %time as with %timeit, using the double-percent-sign cell magic syntax allows timing of multiline scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 905 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A program is made of many single statements, and sometimes timing these statements in context is more important than timing them on their own. Python contains a built-in code profiler (which you can read about in the Python documentation), but IPython offers a much more convenient way to use this profiler, in the form of the magic function %prun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5):\n",
    "        L = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(L)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun sum_of_lists(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14 function calls in 1.622 seconds\n",
    "\n",
    "   Ordered by: internal time\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        5    1.368    0.274    1.368    0.274 <ipython-input-19-f105717832a2>:4(<listcomp>)\n",
    "        5    0.166    0.033    0.166    0.033 {built-in method builtins.sum}\n",
    "        1    0.067    0.067    1.601    1.601 <ipython-input-19-f105717832a2>:1(sum_of_lists)\n",
    "        1    0.021    0.021    1.622    1.622 <string>:1(<module>)\n",
    "        1    0.000    0.000    1.622    1.622 {built-in method builtins.exec}\n",
    "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line-By-Line Profiling with %lprun\n",
    "\n",
    "The function-by-function profiling of %prun is useful, but sometimes it's more convenient to have a line-by-line profile report. This is not built into Python or IPython, but there is a line_profiler package available for installation that can do this. Start by using Python's packaging tool, pip, to install the line_profiler package\n",
    "\n",
    "`pip install line_profiler`\n",
    "\n",
    "Next, you can use IPython to load the line_profiler IPython extension, offered as part of this package:\n",
    "\n",
    "`%load_ext line_profiler`\n",
    "\n",
    "Now the %lprun command will do a line-by-line profiling of any function–in this case, we need to tell it explicitly which functions we're interested in profiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "%lprun -f sum_of_lists sum_of_lists(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memory_profiler\n",
    "\n",
    "Another great 3rd party profiling package is **memory_profiler**. The memory_profiler module can be used for monitoring memory consumption in a process or you can use it for a line-by-line analysis of the memory consumption of your code. Since it’s not included with Python, we’ll have to install it. You can use pip for this:\n",
    "\n",
    "`pip install memory_profiler`\n",
    "\n",
    "Once it’s installed, we need some code to run it against. The memory_profiler actually works in much the same way as line_profiler in that when you run it, memory_profiler will inject an instance of itself into **__builtins__** named profile that you are supposed to use as a decorator on the function you are profiling. Here’s a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memo_prof.py \n",
    "#@profile\n",
    "def mem_func():\n",
    "    lots_of_numbers = list(range(1500))\n",
    "    x = ['letters'] * (5 ** 10)\n",
    "    del lots_of_numbers\n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mem_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we create a list that contains 1500 integers. Then we create a list with 9765625 (5 to the 10 power) instances of a string. Finally we delete the first list and return. The memory_profiler doesn’t have another script you need to run to do the actual profiling like line_profiler did. Instead you can just run Python and use its -m parameter on the command line to load the module and run it against our script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m memory_profiler memo_prof.py \n",
    "Filename: memo_prof.py\n",
    "\n",
    "Line #    Mem usage    Increment   Line Contents\n",
    "================================================\n",
    "     1   16.672 MiB    0.000 MiB   @profile\n",
    "     2                             def mem_func():\n",
    "     3   16.707 MiB    0.035 MiB       lots_of_numbers = list(range(1500))\n",
    "     4   91.215 MiB   74.508 MiB       x = ['letters'] * (5 ** 10)\n",
    "     5   91.215 MiB    0.000 MiB       del lots_of_numbers\n",
    "     6   91.215 MiB    0.000 MiB       return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are pretty self-explanatory this time around. We have our line numbers and then the amount of memory used after said line was executed. Next we have an increment field which tells us the difference in memory of the current line versus the line previous. The very last column is for the code itself.\n",
    "\n",
    "The memory_profiler also includes mprof which can be used to create full memory usage reports over time instead of line-by-line. It’s very easy to use; just take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ mprof run memo_prof.py \n",
    "mprof: Sampling memory every 0.1s\n",
    "running as a Python program..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mprof can also create a graph that shows you how your application consumed memory over time. To get the graph, all you need to do is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ mprof plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%load_ext memory_profiler`\n",
    "\n",
    "The memory profiler extension contains two useful magic functions: the %memit magic (which offers a memory-measuring equivalent of %timeit) and the %mprun function (which offers a memory-measuring equivalent of %lprun). The %memit function can be used rather simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 125.15 MiB, increment: 74.17 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "%memit sum_of_lists(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a line-by-line description of memory use, we can use the %mprun magic. Unfortunately, this magic works only for functions defined in separate modules rather than the notebook itself, so we'll start by using the %%file magic to create a simple module called mprun_demo.py, which contains our sum_of_lists function, with one addition that will make our memory profiling results more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file mprun_demo.py\n",
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5):\n",
    "        L = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(L)\n",
    "        del L # remove reference to L\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mprun_demo import sum_of_lists\n",
    "%mprun -f sum_of_lists sum_of_lists(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profilehooks\n",
    "\n",
    "The last 3rd party package that we will look at in this chapter is called profilehooks. It is a collection of decorators specifically designed for profiling functions. To install profilehooks, just do the following:\n",
    "\n",
    "`pip install profilehooks`\n",
    "\n",
    "Now that we have it installed, let’s re-use the example from the last section and modify it slightly to use profilehooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profhooks.py\n",
    "from profilehooks import profile\n",
    "\n",
    "\n",
    "#@profile\n",
    "def mem_func():\n",
    "    lots_of_numbers = list(range(1500))\n",
    "    x = ['letters'] * (5 ** 10)\n",
    "    del lots_of_numbers\n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mem_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All you need to do to use profilehooks is import it and then decorate the function that you want to profile. If you run the code above, you will get output similar to the following sent to stdout:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output for this package appears to follow that of the cProfile module from Python’s standard library. You can refer to the descriptions of the columns earlier in this chapter to see what these mean. The profilehooks package has two more decorators. The first one we will look at is called timecall. It gives us the course run time of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  mem_func (<ipython-input-9-31bb8e8fb88d>:4):\n",
      "    0.114 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# profhooks2.py\n",
    "from profilehooks import timecall\n",
    "\n",
    "@timecall\n",
    "def mem_func():\n",
    "    lots_of_numbers = list(range(1500))\n",
    "    x = ['letters'] * (5 ** 10)\n",
    "    del lots_of_numbers\n",
    "    return None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mem_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All decorator does is time the execution time of the function but without the overhead of profiling. It’s kind of like using timeit.\n",
    "\n",
    "The last decorator that profhooks provides is called coverage. It is supposed to print out the line coverage of a single function. I didn’t really find this one all that useful myself, but you’re welcome to give it a try on your own.\n",
    "\n",
    "Finally I just want to mention that you can also run profilehooks on the command line using Python’s -m flag:\n",
    "    \n",
    "`python -m profilehooks mymodule.py`\n",
    "\n",
    "The profilehooks package is pretty new, but I think it has some potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
